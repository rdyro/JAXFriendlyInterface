{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import time\n",
    "\n",
    "#from jaxfi import jaxm\n",
    "import numpy as np\n",
    "import jax.dlpack\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.utils.dlpack\n",
    "from jax import Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(x: Array | Tensor, via: str = \"dlpack\", device: str = \"cuda\"):\n",
    "    assert via in (\"dlpack\", \"cpu\")\n",
    "    if isinstance(x, Array):\n",
    "        if via == \"dlpack\":\n",
    "            return torch.utils.dlpack.from_dlpack(jax.dlpack.to_dlpack(x))\n",
    "        else:\n",
    "            return torch.as_tensor(np.array(x), device=device)\n",
    "    else:\n",
    "        if via == \"dlpack\":\n",
    "            return jax.dlpack.from_dlpack(torch.utils.dlpack.to_dlpack(x))\n",
    "        else:\n",
    "            return jax.device_put(jax.numpy.array(x.detach().cpu().numpy()), device=jax.devices(device)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfer(jaxm.rand((10), device=\"cuda\"), device=\"cuda\")\n",
    "transfer(torch.randn(10, device=\"cuda\"), via=\"cpu\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_transfer(*args, **kw):\n",
    "    trials = 3\n",
    "    ret = transfer(*args, **kw)\n",
    "    t = time.time()\n",
    "    for _ in range(trials):\n",
    "        ret = transfer(*args, **kw)\n",
    "    t = time.time() - t\n",
    "    print(f\"{type(args[0])} {kw} = {t / trials:.4e} s\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.ArrayImpl'> {'via': 'dlpack', 'device': 'cpu'} = 9.4573e-06 s\n",
      "Operation on took 2.0425e-02 s\n",
      "<class 'torch.Tensor'> {'via': 'dlpack', 'device': 'cpu'} = 5.0863e-05 s\n",
      "Operation on took 1.1913e-01 s\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'> {'via': 'dlpack', 'device': 'cuda'} = 1.1444e-05 s\n",
      "Operation on took 3.2028e-05 s\n",
      "<class 'torch.Tensor'> {'via': 'dlpack', 'device': 'cuda'} = 4.5458e-05 s\n",
      "Operation on took 8.4257e-04 s\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'> {'via': 'cpu', 'device': 'cpu'} = 8.4309e-02 s\n",
      "Operation on took 1.9971e-02 s\n",
      "<class 'torch.Tensor'> {'via': 'cpu', 'device': 'cpu'} = 4.1650e-01 s\n",
      "Operation on took 8.3929e-02 s\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'> {'via': 'cpu', 'device': 'cuda'} = 6.9831e-02 s\n",
      "Operation on took 6.6837e-05 s\n",
      "<class 'torch.Tensor'> {'via': 'cpu', 'device': 'cuda'} = 1.5130e-01 s\n",
      "Operation on took 1.9184e-02 s\n"
     ]
    }
   ],
   "source": [
    "shape = (10 ** 4, 10 ** 4)\n",
    "for via in [\"dlpack\", \"cpu\"]:\n",
    "    for device in [\"cpu\", \"cuda\"]:\n",
    "        for x in [jaxm.ones(shape, device=device), torch.randn(shape, device=device)]:\n",
    "            x2 = time_transfer(x, via=via, device=device)\n",
    "            if isinstance(x, Array):\n",
    "                expected_device = torch.device(\"cuda:0\" if device == \"cuda\" else device)\n",
    "                assert isinstance(x2, Tensor) and x2.device == expected_device\n",
    "                trials, t = 3, time.time()\n",
    "                for _ in range(trials):\n",
    "                    torch.sum(x2)\n",
    "                t = time.time() - t\n",
    "                print(f\"Operation on took {t / trials:.4e} s\")\n",
    "            else:\n",
    "                assert isinstance(x2, Array) and x2.device() == jaxm.resolve_device(device)\n",
    "                trials, t = 3, time.time()\n",
    "                for _ in range(trials):\n",
    "                    jaxm.sum(x2).block_until_ready()\n",
    "                t = time.time() - t\n",
    "                print(f\"Operation on took {t / trials:.4e} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Shapes must be 1D sequences of concrete values of integer type, got [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jax\u001b[39m.\u001b[39;49mShapedArray(jax\u001b[39m.\u001b[39;49mnumpy\u001b[39m.\u001b[39;49mzeros(\u001b[39m10\u001b[39;49m), dtype\u001b[39m=\u001b[39;49mjax\u001b[39m.\u001b[39;49mnumpy\u001b[39m.\u001b[39;49mfloat32)\n",
      "File \u001b[0;32m~/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/core.py:1493\u001b[0m, in \u001b[0;36mShapedArray.__init__\u001b[0;34m(self, shape, dtype, weak_type, named_shape)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, shape, dtype, weak_type\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, named_shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1493\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape \u001b[39m=\u001b[39m canonicalize_shape(shape)\n\u001b[1;32m   1494\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m _dtype_object(dtype)\n\u001b[1;32m   1495\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweak_type \u001b[39m=\u001b[39m weak_type\n",
      "File \u001b[0;32m~/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/core.py:2039\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   2038\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m-> 2039\u001b[0m \u001b[39mraise\u001b[39;00m _invalid_shape_error(shape, context)\n",
      "\u001b[0;31mTypeError\u001b[0m: Shapes must be 1D sequences of concrete values of integer type, got [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]."
     ]
    }
   ],
   "source": [
    "jax.ShapedArray(jax.numpy.zeros(10), dtype=jax.numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Untraced JAX function did work.\n",
      "Traced JAX function did NOT work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 14:18:19.277519: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2432] Execution of replica 0 failed: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.custom_call' failed: CpuCallback error: RuntimeError: data must be a Tensor\n",
      "\n",
      "At:\n",
      "  /tmp/ipykernel_942670/4080544319.py(19): transfer\n",
      "  /tmp/ipykernel_942670/4080544319.py(28): g\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/debugging.py(227): _flat_callback\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/debugging.py(85): debug_callback_impl\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/debugging.py(146): _callback\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/interpreters/mlir.py(1810): _wrapped_callback\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/interpreters/pxla.py(1908): __call__\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/profiler.py(314): wrapper\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/pjit.py(1252): _pjit_call_impl\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/core.py(817): process_primitive\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/core.py(363): bind_with_trace\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/core.py(2592): bind\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/pjit.py(185): _python_pjit_helper\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/pjit.py(238): cache_miss\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/traceback_util.py(166): reraise_with_filtered_traceback\n",
      "  /tmp/ipykernel_942670/4080544319.py(41): <module>\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3505): run_code\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3445): run_ast_nodes\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3266): run_cell_async\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3061): _run_cell\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3006): run_cell\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel/zmqshell.py(540): run_cell\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel/ipkernel.py(422): do_execute\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel/kernelbase.py(729): execute_request\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel/kernelbase.py(409): dispatch_shell\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel/kernelbase.py(502): process_one\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel/kernelbase.py(513): dispatch_queue\n",
      "  /home/rdyro/.pyenv/versions/3.9.13/lib/python3.9/asyncio/events.py(80): _run\n",
      "  /home/rdyro/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py(1905): _run_once\n",
      "  /home/rdyro/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py(601): run_forever\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/tornado/platform/asyncio.py(195): start\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel/kernelapp.py(725): start\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/traitlets/config/application.py(1043): launch_instance\n",
      "  /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/ipykernel_launcher.py(17): <module>\n",
      "  /home/rdyro/.pyenv/versions/3.9.13/lib/python3.9/runpy.py(87): _run_code\n",
      "  /home/rdyro/.pyenv/versions/3.9.13/lib/python3.9/runpy.py(197): _run_module_as_main\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import jax.dlpack\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.utils.dlpack\n",
    "from jax import Array\n",
    "\n",
    "def transfer(x: Array | Tensor, via: str = \"dlpack\", device: str = \"cuda\"):\n",
    "    assert via in (\"dlpack\", \"cpu\")\n",
    "    if isinstance(x, Array):\n",
    "        if via == \"dlpack\":\n",
    "            return torch.utils.dlpack.from_dlpack(jax.dlpack.to_dlpack(x))\n",
    "        else:\n",
    "            return torch.as_tensor(np.array(x), device=device)\n",
    "    else:\n",
    "        if via == \"dlpack\":\n",
    "            return jax.dlpack.from_dlpack(torch.utils.dlpack.to_dlpack(x))\n",
    "        else:\n",
    "            return jax.device_put(jax.array(x.detach().cpu().numpy()), device=jax.devices(device)[0])\n",
    "\n",
    "def f(x: Array) -> Array:\n",
    "    device = \"cuda\"\n",
    "    z = x\n",
    "    def g(y):\n",
    "        nonlocal z\n",
    "        return transfer(torch.sum(transfer(y, via=\"dlpack\", device=device)), via=\"dlpack\", device=device)\n",
    "\n",
    "    return jax.debug.callback(g, x)\n",
    "\n",
    "r = jax.device_put(jax.numpy.ones(1000).astype(jax.numpy.float32), jax.devices(\"cuda\")[0])\n",
    "\n",
    "try:\n",
    "    print(f(r))\n",
    "    print(\"Untraced JAX function did work.\")\n",
    "except:\n",
    "    print(\"Untraced JAX function did NOT work.\")\n",
    "\n",
    "try:\n",
    "    print(jax.jit(f)(r))\n",
    "    print(\"Traced JAX function did work.\")\n",
    "except:\n",
    "    print(\"Traced JAX function did NOT work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = jax.jit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fn.lower(jax.numpy.zeros(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = out.compiler_ir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lib import xla_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function CustomCall in module jaxlib.xla_extension.ops:\n",
      "\n",
      "CustomCall(...) method of builtins.PyCapsule instance\n",
      "    CustomCall(builder: jaxlib.xla_extension.XlaBuilder, call_target_name: bytes, operands: Span[jaxlib.xla_extension.XlaOp], shape: jaxlib.xla_extension.Shape, opaque: bytes = b'', has_side_effect: bool = False, schedule: jaxlib.xla_extension.ops.CustomCallSchedule = <CustomCallSchedule.SCHEDULE_NONE: 0>, api_version: jaxlib.xla_extension.ops.CustomCallApiVersion = <CustomCallApiVersion.API_VERSION_ORIGINAL: 1>) -> jaxlib.xla_extension.XlaOp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xla_client.ops.CustomCall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PjitFunction' object has no attribute 'to_pycapsule'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fn\u001b[39m.\u001b[39;49mto_pycapsule()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PjitFunction' object has no attribute 'to_pycapsule'"
     ]
    }
   ],
   "source": [
    "fn.to_pycapsule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module @jit_f {\n",
      "  func.func public @main(%arg0: tensor<5xf64> {jax.arg_info = \"x\", mhlo.sharding = \"{replicated}\"}) {\n",
      "    %0 = stablehlo.constant dense<94202629491968> : tensor<i64>\n",
      "    %1 = stablehlo.custom_call @xla_python_gpu_callback(%0, %arg0) {api_version = 2 : i32, backend_config = \"94202629491968\", has_side_effect = true, mhlo.sharding = \"{maximal device=0}\", operand_layouts = [dense<> : tensor<0xindex>, dense<0> : tensor<1xindex>], result_layouts = []} : (tensor<i64>, tensor<5xf64>) -> tuple<>\n",
      "    return\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jax._src.interpreters.partial_eval.DynamicJaxprTracer'>\n",
      "Traced<ShapedArray(float32[3])>with<DynamicJaxprTrace(level=1/0)>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument to to_dlpack must be a jax.Array, got <class 'jax._src.interpreters.partial_eval.DynamicJaxprTracer'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(jaxm\u001b[39m.\u001b[39;49mjit(f)(r))\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[144], line 13\u001b[0m, in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39m#l[0] = np.sum(y)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39m1.0\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 13\u001b[0m g(x)\n\u001b[1;32m     15\u001b[0m \u001b[39m#ret = jaxm.jax.pure_callback(g, shape, ())\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#jaxm.jax.debug.callback(g, x)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m#jaxm.jax.experimental.io_callback(g, shape, x)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m ret \u001b[39m=\u001b[39m l[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[144], line 9\u001b[0m, in \u001b[0;36mf.<locals>.g\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(y))\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(y[:\u001b[39m3\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m l[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(transfer(y, via\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdlpack\u001b[39;49m\u001b[39m\"\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     10\u001b[0m \u001b[39m#l[0] = np.sum(y)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39m1.0\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "Cell \u001b[0;32mIn[81], line 5\u001b[0m, in \u001b[0;36mtransfer\u001b[0;34m(x, via, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, Array):\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m via \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdlpack\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdlpack\u001b[39m.\u001b[39mfrom_dlpack(jaxm\u001b[39m.\u001b[39;49mjax\u001b[39m.\u001b[39;49mdlpack\u001b[39m.\u001b[39;49mto_dlpack(x))\n\u001b[1;32m      6\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mas_tensor(np\u001b[39m.\u001b[39marray(x), device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/dlpack.py:43\u001b[0m, in \u001b[0;36mto_dlpack\u001b[0;34m(x, take_ownership)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a DLPack tensor that encapsulates a ``DeviceArray`` `x`.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[39mTakes ownership of the contents of ``x``; leaves `x` in an invalid/deleted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m    owns.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, array\u001b[39m.\u001b[39mArrayImpl):\n\u001b[0;32m---> 43\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mArgument to to_dlpack must be a jax.Array, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mdevices()) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m xla_client\u001b[39m.\u001b[39m_xla\u001b[39m.\u001b[39mbuffer_to_dlpack_managed_tensor(\n\u001b[1;32m     47\u001b[0m     x\u001b[39m.\u001b[39maddressable_data(\u001b[39m0\u001b[39m), take_ownership\u001b[39m=\u001b[39mtake_ownership)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument to to_dlpack must be a jax.Array, got <class 'jax._src.interpreters.partial_eval.DynamicJaxprTracer'>"
     ]
    }
   ],
   "source": [
    "print(jaxm.jit(f)(r))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom interpreters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.interpreters import mlir, partial_eval as pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function abstract_eval_fun in module jax._src.interpreters.partial_eval:\n",
      "\n",
      "abstract_eval_fun(fun, *avals, debug_info=None, **params)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pe.abstract_eval_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module jax.interpreters.partial_eval in jax.interpreters:\n",
      "\n",
      "NAME\n",
      "    jax.interpreters.partial_eval\n",
      "\n",
      "DESCRIPTION\n",
      "    # Copyright 2018 The JAX Authors.\n",
      "    #\n",
      "    # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "    # you may not use this file except in compliance with the License.\n",
      "    # You may obtain a copy of the License at\n",
      "    #\n",
      "    #     https://www.apache.org/licenses/LICENSE-2.0\n",
      "    #\n",
      "    # Unless required by applicable law or agreed to in writing, software\n",
      "    # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "    # See the License for the specific language governing permissions and\n",
      "    # limitations under the License.\n",
      "\n",
      "DATA\n",
      "    AbstractedAxesSpec = typing.Union[typing.Dict[int, typing.Hashable], t...\n",
      "    AbstractedAxisName = typing.Hashable\n",
      "        A generic version of collections.abc.Hashable.\n",
      "    \n",
      "    Const = typing.Any\n",
      "        Special type indicating an unconstrained type.\n",
      "        \n",
      "        - Any is compatible with every type.\n",
      "        - Any assumed to have all methods.\n",
      "        - All values assumed to be instances of Any.\n",
      "        \n",
      "        Note that all the above statements are true from the point of view of\n",
      "        static type checkers. At runtime, Any should not be used with instance\n",
      "        or class checks.\n",
      "    \n",
      "    ConstFoldRule = typing.Callable[[typing.List[typing.Optional[typ....An...\n",
      "    DCERule = typing.Callable[[typing.List[bool], jax._src.cor...[bool], t...\n",
      "    ForwardingRule = typing.Callable[[jax._src.core.JaxprEqn], typing....V...\n",
      "    JaxprTracerRecipe = typing.Union[ForwardRef('JaxprEqnRecipe'), Forwa.....\n",
      "    ParamsUpdater = typing.Callable[[typing.Sequence[bool], typing.S...ool...\n",
      "    PartialEvalCustomResult = typing.Tuple[typing.Optional[jax._src.core.J...\n",
      "    PartialEvalCustomRule = typing.Callable[[typing.Callable[..., bool], t...\n",
      "    ResAvalUpdater = typing.Callable[[typing.Dict[str, typing.Any], j...co...\n",
      "    Val = typing.Any\n",
      "        Special type indicating an unconstrained type.\n",
      "        \n",
      "        - Any is compatible with every type.\n",
      "        - Any assumed to have all methods.\n",
      "        - All values assumed to be instances of Any.\n",
      "        \n",
      "        Note that all the above statements are true from the point of view of\n",
      "        static type checkers. At runtime, Any should not be used with instance\n",
      "        or class checks.\n",
      "    \n",
      "    call_param_updaters = {closed_call: <function _closed_call_param_updat...\n",
      "    call_partial_eval_rules = {}\n",
      "    close_jaxpr = <jaxlib.xla_extension.WeakrefLRUCache object>\n",
      "    config = <jax._src.config.Config object>\n",
      "    const_fold_rules = {convert_element_type: <function _convert_elt_type_...\n",
      "    convert_constvars_jaxpr = <jaxlib.xla_extension.WeakrefLRUCache object...\n",
      "    convert_invars_to_constvars = <jaxlib.xla_extension.WeakrefLRUCache ob...\n",
      "    custom_partial_eval_rules = {pjit: <function _pjit_partial_eval>, broa...\n",
      "    custom_staging_rules = {pjit: <function pjit_staging_rule>, dynamic_sl...\n",
      "    dce_rules = {call: <function dce_jaxpr_call_rule>, closed_call: <funct...\n",
      "    forwarding_rules = {convert_element_type: <function _convert_elt_type_...\n",
      "    padding_rules = {dynamic_slice: <function _dynamic_slice_padding_rule>...\n",
      "    partial_eval_jaxpr_custom_rules = {call: functools.partial(<function c...\n",
      "    partial_eval_wrapper_nounits = functools.partial(<function transformat...\n",
      "    trace_to_subjaxpr = functools.partial(<function transformation at 0x.....\n",
      "    trace_to_subjaxpr_nounits = functools.partial(<function transformation...\n",
      "    trace_to_subjaxpr_nounits_dyn = functools.partial(<function transforma...\n",
      "    trace_to_subjaxpr_nounits_fwd = functools.partial(<function transforma...\n",
      "\n",
      "FILE\n",
      "    /home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/interpreters/partial_eval.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(jax.interpreters.partial_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'callback' from 'jax.experimental' (/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/experimental/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m callback\n\u001b[1;32m      2\u001b[0m help(callback)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'callback' from 'jax.experimental' (/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/jax/experimental/__init__.py)"
     ]
    }
   ],
   "source": [
    "from jax.experimental import callback\n",
    "help(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'jax.experimental' has no attribute 'callback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jax\u001b[39m.\u001b[39;49mexperimental\u001b[39m.\u001b[39;49mcallback\n",
      "File \u001b[0;32m~/.pyenv/versions/devel/lib/python3.9/site-packages/jax/_src/deprecations.py:53\u001b[0m, in \u001b[0;36mdeprecation_getattr.<locals>.getattr\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m   \u001b[39mreturn\u001b[39;00m fn\n\u001b[0;32m---> 53\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'jax.experimental' has no attribute 'callback'"
     ]
    }
   ],
   "source": [
    "jax.experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax._src import core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function raise_to_shaped in module jax._src.core:\n",
      "\n",
      "raise_to_shaped(aval: 'AbstractValue', weak_type=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(core.raise_to_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_callback_p = core.Primitive(\"io_callback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_bind_params() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m io_callback_p\u001b[39m.\u001b[39;49mget_bind_params()\n",
      "\u001b[0;31mTypeError\u001b[0m: get_bind_params() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "io_callback_p.get_bind_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function emit_python_callback in module jax._src.interpreters.mlir:\n",
      "\n",
      "emit_python_callback(ctx: 'LoweringRuleContext', callback, token: 'Optional[Any]', operands: 'List[ir.Value]', operand_avals: 'List[core.ShapedArray]', result_avals: 'List[core.ShapedArray]', has_side_effect: 'bool', *, sharding: 'Optional[xc.OpSharding]' = None, operand_layouts: 'Optional[Sequence[Optional[Sequence[int]]]]' = None, result_layouts: 'Optional[Sequence[Optional[Sequence[int]]]]' = None) -> 'Tuple[List[ir.Value], Any, Any]'\n",
      "    Emits MLIR that calls back to a provided Python function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlir.emit_python_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
